{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tp = 0\n",
    "global_fp = 0\n",
    "global_fn = 0\n",
    "\n",
    "# model_path = '../datasets/shopping-trolley-5/runs/detect/pretrainedv8n/weights/bestpretrainedv8n.pt'\n",
    "model_path = '../datasets/shopping-trolley-5/runs/detect/unpretrainedv8n/weights/bestpretrainedv8n.pt'\n",
    "image_path = '../shopping-trolley-5/test/images'\n",
    "label_path = '../shopping-trolley-5/test/labels'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = YOLO(model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(image_dir):\n",
    "    predictions = []\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            path = os.path.join(image_dir, filename)\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_tensor = torch.from_numpy(image).float() / 255.0\n",
    "            image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "            # print(image, image.shape)\n",
    "            with torch.no_grad():\n",
    "                detections = model(image_tensor, verbose=False)\n",
    "                predictions.append(detections[0].boxes.xywh / 640)\n",
    "            \n",
    "            images.append(image_tensor)\n",
    "            filenames.append(filename)\n",
    "\n",
    "    return predictions, images, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ground(filename, label_path):\n",
    "    # TO SAVE ALL GROUNDS INTO CSV FILE\n",
    "    path = os.path.join(label_path, filename + '.txt')\n",
    "    bounding_boxes = [] \n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            components = line.strip().split()\n",
    "            if len(components) >= 5:\n",
    "                x = float(components[1])\n",
    "                y = float(components[2])\n",
    "                w = float(components[3])\n",
    "                h = float(components[4])\n",
    "                bounding_boxes.append([x, y, w, h])\n",
    "\n",
    "    return np.array(bounding_boxes)\n",
    "\n",
    "def write_to_csv(filenames, predictions, label_path, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Filename', 'Type', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "        for i in range(len(predictions)):\n",
    "            filename_base = filenames[i][:-4]\n",
    "\n",
    "            ground_truths = print_ground(filename_base, label_path)\n",
    "            for ground in ground_truths:\n",
    "                writer.writerow([filenames[i], 'Ground'] + ground.tolist())\n",
    "\n",
    "            if len(predictions[i]) > 0:\n",
    "                for prediction in predictions[i]:\n",
    "                    writer.writerow([filenames[i], 'Predicted'] + prediction.tolist())\n",
    "            else:\n",
    "                writer.writerow([filenames[i], 'Predicted', '-1', '-1', '-1', '-1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, image, filenames = predict_images(image_path)\n",
    "write_to_csv(filenames, predictions, label_path, 'result.csv')\n",
    "data = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate the Intersection over Union (IoU) of two bounding boxes.\"\"\"\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = area1 + area2 - intersection_area\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read the CSV data into a structure organized by filename and type.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename)\n",
    "    grouped = defaultdict(lambda: {'Ground': [], 'Predicted': []})\n",
    "    for _, row in data.iterrows():\n",
    "        grouped[row['Filename']][row['Type']].append([row['x'], row['y'], row['w'], row['h']])\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def match_predictions_to_ground_truths(ground_boxes, predicted_boxes, max_distance=50):\n",
    "    global global_tp, global_fp, global_fn\n",
    "    match_found = False\n",
    "    \"\"\"Match predictions to ground truths based on the center distance threshold.\"\"\"\n",
    "    matches = []\n",
    "    used_predictions = set()\n",
    "\n",
    "    for i, ground_box in enumerate(ground_boxes):\n",
    "        ground_center_x = (ground_box[0] + ground_box[2]) / 2\n",
    "        ground_center_y = (ground_box[1] + ground_box[3]) / 2\n",
    "        best_distance = float('inf')\n",
    "        best_pred_index = -1\n",
    "\n",
    "        for j, predicted_box in enumerate(predicted_boxes):\n",
    "            if j in used_predictions:\n",
    "                continue\n",
    "\n",
    "            pred_center_x = (predicted_box[0] + predicted_box[2]) / 2\n",
    "            pred_center_y = (predicted_box[1] + predicted_box[3]) / 2\n",
    "\n",
    "            dist_x = abs(pred_center_x - ground_center_x)\n",
    "            dist_y = abs(pred_center_y - ground_center_y)\n",
    "\n",
    "            if dist_x < max_distance and dist_y < max_distance:\n",
    "                global_tp += 1\n",
    "                match_found = True\n",
    "                # Calculate Euclidean distance just for finding the closest box\n",
    "                distance = (dist_x**2 + dist_y**2)**0.5\n",
    "                if distance < best_distance:\n",
    "                    best_distance = distance\n",
    "                    best_pred_index = j\n",
    "\n",
    "        if best_distance < float('inf') and best_pred_index != -1:\n",
    "            matches.append((i, best_pred_index))\n",
    "            used_predictions.add(best_pred_index)\n",
    "\n",
    "        if not match_found:\n",
    "            global_fn += 1\n",
    "\n",
    "    for j in range(len(predicted_boxes)):\n",
    "        if j not in used_predictions:\n",
    "            global_fp += 1    \n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def draw_bboxes_and_calculate_iou(image_path, grounds, predictions):\n",
    "    image = Image.open(image_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ground_boxes = []\n",
    "    predicted_boxes = []\n",
    "\n",
    "    for index, row in grounds.iterrows():\n",
    "        x1 = (row['x'] - row['w'] / 2) * image.width\n",
    "        y1 = (row['y'] - row['h'] / 2) * image.height\n",
    "        x2 = (row['x'] + row['w'] / 2) * image.width\n",
    "        y2 = (row['y'] + row['h'] / 2) * image.height\n",
    "        ground_boxes.append((x1, y1, x2, y2))\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    for index, row in predictions.iterrows():\n",
    "        x1 = (row['x'] - row['w'] / 2) * image.width\n",
    "        y1 = (row['y'] - row['h'] / 2) * image.height\n",
    "        x2 = (row['x'] + row['w'] / 2) * image.width\n",
    "        y2 = (row['y'] + row['h'] / 2) * image.height\n",
    "        predicted_boxes.append((x1, y1, x2, y2))\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='green', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    matches = match_predictions_to_ground_truths(ground_boxes, predicted_boxes)\n",
    "    for match in matches:\n",
    "        ground_idx, pred_idx = match  # Adjusted to expect only two elements\n",
    "        print(f\"Match found between Ground Box {ground_idx} and Prediction Box {pred_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall mean IoU for the dataset is: 0.8693\n"
     ]
    }
   ],
   "source": [
    "def convert_to_corners(x, y, w, h, image_width, image_height):\n",
    "    x1 = (x - w / 2) * image_width\n",
    "    y1 = (y - h / 2) * image_height\n",
    "    x2 = (x + w / 2) * image_width\n",
    "    y2 = (y + h / 2) * image_height\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def calculate_image_iou(ground_boxes, predicted_boxes):\n",
    "    iou_scores = []\n",
    "    used_predictions = set()\n",
    "\n",
    "    for i, ground_box in enumerate(ground_boxes):\n",
    "        best_iou = 0\n",
    "        best_pred_index = -1\n",
    "\n",
    "        for j, predicted_box in enumerate(predicted_boxes):\n",
    "            if j in used_predictions:\n",
    "                continue\n",
    "            iou = calculate_iou(ground_box, predicted_box)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_pred_index = j\n",
    "\n",
    "        if best_iou > 0:  # Only consider positive IoUs to calculate mean\n",
    "            iou_scores.append(best_iou)\n",
    "            used_predictions.add(best_pred_index)\n",
    "\n",
    "    return np.mean(iou_scores) if iou_scores else 0\n",
    "\n",
    "def overall_dataset_iou(data):\n",
    "    filenames = data['Filename'].unique()\n",
    "    overall_iou = []\n",
    "\n",
    "    image_width = 640 # TODO: Adjust!\n",
    "    image_height = 640 # TODO: Adjust!\n",
    "\n",
    "    for filename in filenames:\n",
    "        ground_data = data[(data['Filename'] == filename) & (data['Type'] == 'Ground')]\n",
    "        pred_data = data[(data['Filename'] == filename) & (data['Type'] == 'Predicted')]\n",
    "\n",
    "        ground_boxes = [convert_to_corners(row['x'], row['y'], row['w'], row['h'], image_width, image_height) for index, row in ground_data.iterrows()]\n",
    "        predicted_boxes = [convert_to_corners(row['x'], row['y'], row['w'], row['h'], image_width, image_height) for index, row in pred_data.iterrows()]\n",
    "\n",
    "        file_iou = calculate_image_iou(ground_boxes, predicted_boxes)\n",
    "        overall_iou.append(file_iou)\n",
    "\n",
    "    return np.mean(overall_iou)\n",
    "\n",
    "iou_result = overall_dataset_iou(data)\n",
    "print(f\"The overall mean IoU for the dataset is: {iou_result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = data['Filename'].unique()\n",
    "for filename in filenames:\n",
    "    grounds = data[(data['Filename'] == filename) & (data['Type'] == 'Ground')]\n",
    "    predictions = data[(data['Filename'] == filename) & (data['Type'] == 'Predicted')]\n",
    "    image_path = os.path.join('../shopping-trolley-5/test/images', filename)\n",
    "    draw_bboxes_and_calculate_iou(image_path, grounds, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543 128 37\n",
      "0.8092399403874814 0.9362068965517242 0.86810551558753\n"
     ]
    }
   ],
   "source": [
    "print(global_tp, global_fp, global_fn)\n",
    "precision = global_tp / (global_tp + global_fp)\n",
    "recall = global_tp / (global_tp + global_fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(precision, recall, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
